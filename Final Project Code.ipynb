{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3a81d9b0-4d78-45f9-bebb-99bf902d9b09",
   "metadata": {},
   "source": [
    "Dataset\n",
    "Team 48 \n",
    "1000 samples\n",
    "13 features original. 9 Features after removing repeated info. \n",
    "Please explain in report feature selection on data analysis.\n",
    "\n",
    "3 out of the 9 are categorical. \n",
    "\n",
    "2 of them are 3 categories, the other has 2 categories. \n",
    "predicting charging duration. \n",
    "\n",
    "should one hot encode categorical data. \n",
    "\n",
    "Narrative:\n",
    "Ev owners in general to maximize battery life would be intersted. \n",
    "Simple would be great. Automatically get it charged the best way. \n",
    "Companies responsible for charging stations, and such. \n",
    "\n",
    "Performance metrics\n",
    "\n",
    "Use R2 for performance metric. \n",
    "\n",
    "Models\n",
    "Regression 45 models total\n",
    "+ Linear regression (feature selection for analysis, lasso regularization. 20 models)\n",
    "+ also can turn into logistic regression. (see if prediction becomes better with accuracy). \n",
    "+ Neural networks. 20 models. architecture #number of layers #nodes, activation functions. \n",
    "+ if time allows, add classifcation at the end for the neural networks. \n",
    "+ Random forests 5 models (number trees, threshold amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afd569-8a0b-4f7a-82d3-292e0b785bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Linear Regression \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras import regularizers\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d3efa-d02c-49cf-a51d-d77a53b9e0ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>Data Pre-Processing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00070cb-8df9-47dd-aaa8-0b25e699cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "df = pd.read_csv('ev_battery_charging_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c856e59-4495-48f9-8804-cbca9b12cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any NaN values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Shape after cleaning\n",
    "print(\"\\nAfter removing rows with NaN:\")\n",
    "print(f\"Rows: {df_clean.shape[0]}, Columns: {df_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992edfbf-9e95-4323-954f-cb6ab795d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop inputs calculated from the column we are predicting\n",
    "drop_cols = ['Degradation Rate (%)', 'Efficiency (%)', 'Optimal Charging Duration Class']\n",
    "df_clean = df_clean.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc88382-d338-466f-aa81-4b390abc439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the categorical columns and numerical columns for one-hot encoding later\n",
    "cat_col = ['Charging Mode', 'Battery Type', 'EV Model']\n",
    "num_col = ['SOC (%)', 'Voltage (V)', 'Current (A)', 'Battery Temp (°C)', 'Ambient Temp (°C)', 'Charging Cycles']\n",
    "target = 'Charging Duration (min)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162c306-1cd5-4961-9cb5-ff7a105ccdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the column we are predicting to the end\n",
    "df_clean[target] = df_clean.pop(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc7542-786b-4f02-8288-75353f4f2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df_clean.drop(columns=target)\n",
    "y = df_clean[target]\n",
    "Xtrain_valid, Xtest, ytrain_valid, ytest = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Split the data into train, validate, test\n",
    "\n",
    "Xtrain, Xvalid, ytrain, yvalid = train_test_split(Xtrain_valid, ytrain_valid, test_size=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c31f2-fe4e-4e0b-942e-776830c21950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe7b97-2a9f-4af8-883e-aee0ded715e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baebdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean[target].plot(title='Charge Duration', xlabel='Index', ylabel='Time (min)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor for numerical columns\n",
    "num_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "# Preprocessor for categorical columns\n",
    "cat_transformer = Pipeline(\n",
    "    steps=[(\"encoder\", OneHotEncoder(drop='first'))])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_col),\n",
    "        ('cat', cat_transformer, cat_col)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcde45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_norm = preprocessor.fit_transform(Xtrain)\n",
    "Xvalid_norm = preprocessor.transform(Xvalid)\n",
    "Xtest_norm = preprocessor.transform(Xtest)\n",
    "feature_names_x = preprocessor.get_feature_names_out()\n",
    "Xtrain_norm_df = pd.DataFrame(Xtrain_norm, columns=feature_names_x, index=Xtrain.index)\n",
    "Xvalid_norm_df = pd.DataFrame(Xvalid_norm, columns=feature_names_x, index=Xvalid.index)\n",
    "Xtest_norm_df = pd.DataFrame(Xtest_norm, columns=feature_names_x, index=Xtest.index)\n",
    "\n",
    "ytrain_df = pd.DataFrame(ytrain)\n",
    "yvalid_df = pd.DataFrame(yvalid)\n",
    "ytest_df = pd.DataFrame(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e920341-1d60-4e45-bdde-b7c165004117",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>Linear Regression Models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859e4d5-bdeb-4be0-9790-0c6ca3a7f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with feature selection\n",
    "linreg_pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                     ('linreg', LinearRegression())])\n",
    "\n",
    "# Fit the model\n",
    "linreg_pipe.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026c62d-627b-40f1-8af3-a0e3c9f71862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression R2\n",
    "pred = linreg_pipe.predict(Xtest)\n",
    "r2_lasso = np.max(r2_score(ytest, pred))\n",
    "print(r2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67709098-004b-4c83-b4b7-436ed74d9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = np.logspace(-5, 5, 10)\n",
    "lasso_models = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso_pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                         ('lasso', Lasso(alpha=alpha))])\n",
    "    lasso_pipe.fit(Xtrain, ytrain)\n",
    "    lasso_models.append(lasso_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b3687-1d74-480e-a0a5-9cf400350014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression R2\n",
    "pred_lasso = []\n",
    "r2_lasso = []\n",
    "\n",
    "for i in range(len(alphas)):\n",
    "    pred_lasso.append(lasso_models[i].predict(Xtest))\n",
    "    r2_lasso.append(r2_score(ytest, pred_lasso[i]))\n",
    "\n",
    "r2_lasso_max = max(r2_lasso)\n",
    "print(r2_lasso_max)\n",
    "print(np.argmax(r2_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff70c13-70c6-4d5b-9a8f-d986ad212795",
   "metadata": {},
   "source": [
    "<h2><center>Logistic Regression Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b07f7-b6cc-4341-b54e-a22b019e17f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaeeddc6-af8a-4437-b3bf-a86a2cc23994",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>Neural Networks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be0081",
   "metadata": {},
   "source": [
    "Plan:\n",
    "1. Build a basic NN to get results\n",
    "    a. Build pipeline\n",
    "    b. Build NN model\n",
    "    c. Compile NN w/ pipeline\n",
    "    d. Calculate R2 score and compare with linreg\n",
    "2. Build function to build pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef465cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an MLP\n",
    "\n",
    "ki = GlorotUniform(seed=2434)\n",
    "\n",
    "model_mlp = Sequential([\n",
    "    Dense(64, input_shape=(Xtrain_norm_df.shape[1],), activation='relu', kernel_initializer=ki),\n",
    "    Dense(32, activation='relu', kernel_initializer=ki),\n",
    "    Dense(16, activation='relu', kernel_initializer=ki),\n",
    "    Dense(1, kernel_initializer=ki)\n",
    "])\n",
    "\n",
    "model_mlp.compile( optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"r2_score\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cd5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MLP\n",
    "\n",
    "history_mlp = model_mlp.fit(x=Xtrain_norm_df, y=ytrain_df, epochs=50, validation_data=(Xvalid_norm_df,yvalid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_perf = r2_score(ytrain_df, model_mlp.predict(Xtrain_norm_df))\n",
    "mlp_perf_valid = r2_score(yvalid_df, model_mlp.predict(Xvalid_norm_df))\n",
    "print(mlp_perf)\n",
    "print(mlp_perf_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers, lr, x_data, last_reg_layer):\n",
    "\n",
    "    num_units = np.zeros(num_layers, dtype=int)\n",
    "    num_units[-1] = 1\n",
    "    if num_layers > 1:\n",
    "        for i in range(num_layers-1):\n",
    "            num_units[i] = 2**(num_layers+1-i)\n",
    "\n",
    "    layers = []\n",
    "    ki = GlorotUniform(seed=2434)\n",
    "    layers.append(Dense(num_units[0], input_shape=(x_data.shape[1],), activation='relu', kernel_initializer=ki))\n",
    "    for i in range(1, num_layers-1):\n",
    "        layers.append(Dense(num_units[i], activation='relu', kernel_initializer=ki))\n",
    "    layers.append(Dense(1, kernel_initializer=ki, kernel_regularizer=last_reg_layer))\n",
    "\n",
    "\n",
    "    model = Sequential(layers)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "\n",
    "    model.compile( optimizer=optimizer, loss=\"mse\", metrics=[\"r2_score\"] )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_layers': [2, 3, 4, 5],\n",
    "    'lr': [1e-3, 1e-2, 1e-1],\n",
    "    'last_reg_layer': [None, regularizers.l1(1e-2),\n",
    "                       regularizers.l1(1e-1),\n",
    "                       regularizers.l2(1e-2), regularizers.l2(1e-1)],\n",
    "    'epochs': [10, 25, 50]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combos = list(product(\n",
    "    param_grid['num_layers'],\n",
    "    param_grid['lr'],\n",
    "    param_grid['last_reg_layer'],\n",
    "    param_grid['epochs']   \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a153a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_to_str(reg):\n",
    "    if reg is None:\n",
    "        return \"None\"\n",
    "    elif hasattr(reg, 'l1'):\n",
    "        return f\"L1({reg.l1:.3f})\"   # rounds to 3 decimals\n",
    "    elif hasattr(reg, 'l2'):\n",
    "        return f\"L2({reg.l2:.3f})\"\n",
    "    else:\n",
    "        return str(reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec6e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for num_layers, lr, last_reg_layer, epochs in all_combos:\n",
    "\n",
    "    model = build_model(num_layers, lr, Xtrain_norm_df, last_reg_layer)\n",
    "\n",
    "    history = model.fit(\n",
    "        x = Xtrain_norm_df,\n",
    "        y = ytrain_df,\n",
    "        epochs=epochs,\n",
    "        validation_data = (Xvalid_norm_df, yvalid_df),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_hat_valid = model.predict(Xvalid_norm_df)\n",
    "    perf_valid = r2_score(yvalid_df, y_hat_valid)\n",
    "\n",
    "    y_hat_train = model.predict(Xtrain_norm_df)\n",
    "    perf_train = r2_score(ytrain_df, y_hat_train)\n",
    "\n",
    "    results.append({\n",
    "    'num_layers': num_layers,\n",
    "    'lr': lr,\n",
    "    'last_reg_layer': reg_to_str(last_reg_layer),\n",
    "    'epochs': epochs,\n",
    "    'r2_train': perf_train,\n",
    "    'r2_valid': perf_valid,\n",
    "    'model': model,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992de8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['last_reg_layer'] = results_df['last_reg_layer'].fillna(\"None\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_NN_idx = results_df['r2_valid'].idxmax()\n",
    "best_model_NN = results_df.loc[best_model_NN_idx]\n",
    "best_model_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_NN_idx_train = results_df['r2_train'].idxmax()\n",
    "worst_model_NN_idx = results_df['r2_valid'].idxmin()\n",
    "worst_model_NN_idx_train = results_df['r2_train'].idxmin()\n",
    "\n",
    "best_model_NN_train = results_df.loc[best_model_NN_idx_train]\n",
    "worst_model_NN = results_df.loc[worst_model_NN_idx]\n",
    "worst_model_NN_train = results_df.loc[worst_model_NN_idx_train]\n",
    "\n",
    "best_model_NN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model_NN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = list(param_grid.keys())\n",
    "sweeps = []\n",
    "\n",
    "for i in param_names:\n",
    "    list_param_values = sorted(results_df[i].unique())\n",
    "    param_names_copy = [p for p in param_names if p != i]\n",
    "\n",
    "    sweep = results_df[\n",
    "        (results_df[param_names_copy[0]] == best_model_NN[param_names_copy[0]]) &\n",
    "        (results_df[param_names_copy[1]] == best_model_NN[param_names_copy[1]]) &\n",
    "        (results_df[param_names_copy[2]] == best_model_NN[param_names_copy[2]]) \n",
    "    ]\n",
    "    sweeps.append(sweep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231768ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "bar_width = 0.5\n",
    "names = ['# of Layers', 'Learning Rate', 'Linear Actication Layer', '# of Epochs']\n",
    "\n",
    "for idx, sweep in enumerate(sweeps):\n",
    "    x_vals = sweep[param_names[idx]]\n",
    "    y_vals = sweep['r2_valid']\n",
    "    positions = np.arange(len(x_vals))\n",
    "    \n",
    "    axes[idx].bar(positions, y_vals, width=bar_width, color='red')\n",
    "    axes[idx].set_xticks(positions)\n",
    "    axes[idx].set_xticklabels(x_vals, rotation=45)\n",
    "    axes[idx].set_title(names[idx])\n",
    "    axes[idx].set_ylabel(\"R²\")\n",
    "    axes[idx].set_xlabel(param_names[idx])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4768f6f-ac8d-4835-bba3-9f3510ce127a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>Random Forest\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f51fe2-ee92-443e-9f5e-09480f5e02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "#5 Random Forest models:\n",
    "#RF_1, RF_2, RF_3: increasing n_estimators (50, 100, 200)\n",
    "#RF_4: regularized trees (shallower trees, min leaf = 5)\n",
    "#RF_5: strongly regularized trees (more trees, deeper but min leaf = 10)\n",
    "\n",
    "rf_configs = {\n",
    "    'RF_1 (50 trees)': RandomForestRegressor(\n",
    "        n_estimators=50,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'RF_2 (100 trees)': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'RF_3 (200 trees)': RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'RF_4 (100 trees, depth=10, leaf=5)': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'RF_5 (300 trees, depth=15, leaf=10)': RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=15,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4438a-bd59-486f-87bd-6997334dbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = []\n",
    "rf_fitted_models = {}\n",
    "\n",
    "for name, model in rf_configs.items():\n",
    "    #Training the model and recording training time\n",
    "    start = time.time()\n",
    "    model.fit(Xtrain_norm_df, ytrain_df.values.ravel())\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    #Saving the fitted model\n",
    "    rf_fitted_models[name] = model\n",
    "\n",
    "    #Get predictions on train and validation sets\n",
    "    ytrain_pred = model.predict(Xtrain_norm_df)\n",
    "    yvalid_pred = model.predict(Xvalid_norm_df)\n",
    "\n",
    "    #Computing performance metrics\n",
    "    train_r2 = r2_score(ytrain_df, ytrain_pred)\n",
    "    valid_r2 = r2_score(yvalid_df, yvalid_pred)\n",
    "    valid_mae = mean_absolute_error(yvalid_df, yvalid_pred)\n",
    "    valid_rmse = np.sqrt(mean_squared_error(yvalid_df, yvalid_pred))\n",
    "\n",
    "    #Storing the results\n",
    "    rf_results.append({\n",
    "        'Model': name,\n",
    "        'n_estimators': model.n_estimators,\n",
    "        'max_depth': model.max_depth,\n",
    "        'min_samples_leaf': model.min_samples_leaf,\n",
    "        'Train R²': train_r2,\n",
    "        'Valid R²': valid_r2,\n",
    "        'Valid MAE': valid_mae,\n",
    "        'Valid RMSE': valid_rmse,\n",
    "        'Train Time (s)': train_time\n",
    "    })\n",
    "\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "rf_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b1ab2-a524-4b18-9ca6-8b9e6f196b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting train_r2, valid_r2\n",
    "rf_results_df.plot(\n",
    "    x='Model',\n",
    "    y=['Train R²', 'Valid R²'],\n",
    "    marker='o',\n",
    "    figsize=(8, 4),\n",
    "    title='Random Forest Performance (Train vs Valid R²)'\n",
    ")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9843e-25a2-4a8e-811e-c8b0986e30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting model with highest validation R²\n",
    "best_rf_row = rf_results_df.loc[rf_results_df['Valid R²'].idxmax()]\n",
    "best_rf_name = best_rf_row['Model']\n",
    "best_rf = rf_fitted_models[best_rf_name]\n",
    "\n",
    "print(\"Best RF model (based on validation R²):\")\n",
    "display(best_rf_row[['Model', 'n_estimators', 'max_depth', 'min_samples_leaf', \n",
    "                     'Train R²', 'Valid R²', 'Valid MAE', 'Valid RMSE', 'Train Time (s)']])\n",
    "\n",
    "#Evaluating the best RF model on the test set\n",
    "ytest_pred = best_rf.predict(Xtest_norm_df)\n",
    "test_r2 = r2_score(ytest_df, ytest_pred)\n",
    "test_mae = mean_absolute_error(ytest_df, ytest_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(ytest_df, ytest_pred))\n",
    "\n",
    "print(\"\\nTest performance of best RF model:\")\n",
    "print(f\"Test R²:   {test_r2:.3f}\")\n",
    "print(f\"Test MAE:  {test_mae:.3f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4f699-9fdf-452c-8da4-85a8df94e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing feature importances for all engineered features\n",
    "importances = best_rf.feature_importances_\n",
    "\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': feature_names_x,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee6d01-b01c-4dbe-9794-26bff7d8551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting feature importances for ALL engineered features\n",
    "feat_imp_df.plot(\n",
    "    x='Feature',\n",
    "    y='Importance',\n",
    "    kind='bar',\n",
    "    figsize=(10, 4),\n",
    "    legend=False\n",
    ")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(f\"Feature Importances for All Engineered Features ({best_rf_name})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53de02b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>Extra Workspace\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be900c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812a727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
